{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMIIZOF7fzOUrhtvQ9x1TTy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GZKQjXeW1xe2"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader,TensorDataset\n","from sklearn.model_selection import train_test_split\n","\n","\n","\n","input_file_path = '/Documents/Sasan/DATA_Protein/pssm_all'\n","output_directory = '/Documents/Sasan/DATA_Protein/split_files3/'\n","\n","def process_sequence(part):\n","    lines = part.split('\\n')\n","    header = lines[0]\n","    sequence = ''.join(lines[1:])  # Join all sequence lines into a single string\n","    return header, sequence\n","\n","\n","import re\n","\n","def split_and_process_file(input_file_path, output_directory):\n","    with open(input_file_path, 'r') as file:\n","        content = file.read()\n","\n","    # Use a regular expression to split the file into parts, each starting with '>'\n","    # This pattern matches '>' only at the beginning of a line\n","    parts = re.split(r'(?m)^>', content)[1:]  # The `(?m)` flag enables multiline mode, `^` matches start of a line\n","\n","    for part in parts:\n","        # Since we've split on '>', we need to prepend it back to form the correct header\n","        header, sequence = process_sequence('>' + part)\n","        split_header = header.split('|')\n","        identifier = split_header[2].split(' ')[0]\n","#         print(identifier)\n","        # Check if the split header has at least three elements\n","\n","        # Uncomment and complete these lines if you need to process and save the sequence\n","        processed_content = f\"{identifier},{sequence}\"\n","\n","        output_file_path = f\"{output_directory}{identifier}.pssm\"  # Adjust the extension if needed\n","        with open(output_file_path, 'w') as output_file:\n","            output_file.write(processed_content)\n","\n","split_and_process_file(input_file_path, output_directory)\n","\n","\n","# The comma separated protein sequence file\n","protein_sequence_file = \"/Users/admin/Documents/Desertation/pssm/python-code/ago1-protein.fasta\"\n","# Output directory where the pssm profiles will be stored\n","output_dir = \"/Users/admin/Documents/Desertation/pssm/result/\"\n","# the path to the psiblast program executable downloaded as part of the blast program suite\n","psiblast_executable_path = \"/Users/admin/Documents/Desertation/pssm/ncbi-blast-2.9.0+/bin/psiblast\"\n","# prefix of the indexed blast database files created using makeblastdb\n","blast_db_prefix = \"/Users/admin/Documents/Desertation/pssm/uniref50\"\n","# number of cores to be used while creating the pssm profiles\n","number_of_cores = 8\n","\n","create_pssm_profile(protein_sequence_file, output_dir, psiblast_executable_path,\n","                    blast_db_prefix, number_of_cores)"]}]}